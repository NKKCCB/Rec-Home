一、自监督推荐算法

1.Relative Contrastive Learning for Sequential Recommendation with Similarity-based Positive Sample Selection--From CIKM2024

①动机

​	当前基于对比学习的序列推荐算法，其数据增强的方式如掩码或者替换一些item可能会改变用户的意图（即：增强后的正样本对不是真的正样本了）。监督对比学习SCL可以改善这一点，将相同的Traget Item的序列作为正样本，但是监督学习样本稀疏，缺失了自监督学习的优势。

②方法

​	为了结合二者优势，本文将两种方法结合，同时进行对比学习CL与监督对比学习SCL，提出了相对对比学习。有监督的作为strong CL loss,无监督部分作为weak CL loss。

![image-20250118200212924](https://github.com/NKKCCB/Rec-Home/blob/main/typora-resource/image-20250118200212924.png)



2.BERT4Rec

​	本文是通过BERT做推荐算法。文中提到，之前的算法使用序列神经网络从左向右地编码用户的历史交互信息，提取用户历史兴趣，只利用了单向的信息进行建模。尽管它们是有效的，但是存在两点问题：①单向结构限制了用户行为序列中隐藏表示的能力②之前的序列神经网络经常采用严格有序的序列

​	本文方法使用BRET式的预测方法将预测某一masked item做成了完形填空式的任务。并训练预训练模型用于下游任务。

3.Enhancing CTR Prediction through Sequential Recommendation Pre-training: Introducing the SRP4CTR Framework--From CIKM2024

辅助知识：side infomation：除了用户的行为序列，还有其他很多可以用到的特征，如品类、描述词、物品的历史点击率、时间、地点、天气、上下文等信息，每个特征都可以形成一个与行为序列一一对应的序列，输入模型以辅助预测。这类信息统称为“side information”。行为序列是最重要的信息，因此除了行为序列之外的信息都是side infomation。

①动机

​	本文提出了现有自监督预训练模型在推荐算法CTR预测的两个问题，一是忽略了下游任务的额外推理成本，二是没有考虑如何从预训练模型中转移有效信息。可以总结为一个问题，即预训练与下游任务的差异。

②方法

​	![image-20250119113654005](https://github.com/NKKCCB/Rec-Home/blob/main/typora-resource/image-20250119113654005.png)

​	文章将side infomation分为两类，一个是商品相关的，一个是用户相关的。对于每个item，作者将商品相关的side infomation累加作为一个token,用户相关的side infomation累加作为一个token。作者提出的FG-BERT对两种token分别掩码并预测，作为预训练模型。

​	为了解决预训练的任务：item id与下游实际任务CTR点击率，这两个任务的差异，作者提出了一个query transformer,里面用到的方法也是经典的交叉注意力机制处理的方法：Q来自于id,K和V来自于用户的side infomation,从而建立用户行为和id的强相关。在下游任务种主干网络预测的id输入query transformer，并进行特征融合，从而获取最终的CTR label

​	![image-20250119114710756](https://github.com/NKKCCB/Rec-Home/blob/main/typora-resource/image-20250119114710756.png)

二、大模型与推荐算法

​	1.IDGenRec: LLM-RecSys Alignment with Textual ID Learning--From SIGIR2024

​	①动机

​	不同于传统基于预测概率排名的推荐算法，基于LLM的生成式推荐使用从文本到文本的生成范式。但是当前的生成范式无法使用ID进行推荐的生成（可能主要因为不同于传统NLP，ID不具有太多语义信息），本文目的就是利用ID做生成式推荐。

②方法

​	做法总结起来很简洁：由于真实ID可能不具有语义信息，作者通过item自带的语义信息（side infomation）去训练一个ID生成器，生成的ID与真实ID做损失计算，从而这个ID生成器可以学到语义信息与ID的映射关系。而最主要的LLM部分则不更新参数，仅对生成的具有语义信息的item序列做预测。

**![image-20250119121448937](https://github.com/NKKCCB/Rec-Home/blob/main/typora-resource/image-20250119121448937.png)**

上图为ID生成器，下图为总流程

![image-20250119121429882](https://github.com/NKKCCB/Rec-Home/blob/main/typora-resource/image-20250119121429882.png)

​	2.Can Small Language Models be Good Reasoners for Sequential Recommendation?--From WWW2024

​	LLM在顺序推荐系统中主要有两个挑战：一是用户行为模式的复杂性，单纯依赖LLMs的单步推理可能导致不正确或与任务无关的响应；二是LLMs的资源需求极高，对于实际的顺序推荐系统来说不切实际。为了克服这些挑战，论文提出了一种新颖的框架SLIM，旨在以资源高效的方式让小型语言模型也能具备LLMs的推理能力，从而在顺序推荐任务中生成有意义的推荐理由。

​	SLIM框架的核心思想是通过知识蒸馏策略，将大型教师模型（teacher model）的推理能力转移到小型学生模型（student model）中。为了实现这一目标，论文提出了以下步骤：

1、使用基于用户行为序列的CoT（Chain-of-Thought）提示来引导大型教师模型生成推理理由。

2、将这些理由作为标签，用于微调小型学生模型，使其在推荐任务中获得逐步推理的能力。

3、将经过微调的小型模型直接部署为顺序推荐的知识点生成器，它能够生成与推荐高度相关的高质量推理知识。

![image-20250119122512889](https://github.com/NKKCCB/Rec-Home/blob/main/typora-resource/image-20250119122512889.png)

​	最后，将学生模型生成的推理理由编码为密集向量，并将其应用于推荐系统，与用户信息计算相似度，做出推荐

三、经典序列推荐算法

1.SASRec

​		本文是比较经典的使用Transformer进行序列推荐算法的方法。使用Transfomer应用到各领域的方法当下已经比较普遍，这里主要关注对数据的处理：对于变长的序列s,将其转换为定长的序列n,以输入Transfomer block。规则是如果s长度>n,则取s中最近的n项，如果s<n,则填充0向量作为padding。

​	预测则是通过MF矩阵分解的方式，对user-item所得结果评分排名，得出下一个预测item。

2.Controllable Multi-Interest Framework for Recommendation--From KDD2024

①动机

​	从用户的行为序列给出一个整体的Embedding，对Embedding处理从而预测下一个，然而统一的用户Embedding不能反映用户在一段时间内的多种兴趣。

②方法

​	作者使用**动态路由方法**作为用户行为序列的多兴趣提取模块。将用户行为序列的物品embedding列表看作是使用动态路由方法作为用户行为序列的多兴趣提取模块。将用户行为序列的物品embedding列表看作是最初的胶囊（primary capsules），多元用户兴趣看作是兴趣胶囊（interest capsules）

​	<img src="https://github.com/NKKCCB/Rec-Home/blob/main/typora-resource/image-20250119101019359.png" alt="image-20250119101019359" style="zoom:50%;" />

​		作者的动态路由迭代过程可以看到由一个耦合系数*权重矩阵 *初始胶囊，逐步迭代并做残差计算，得到最终的K个兴趣胶囊。

​		然后兴趣胶囊做通过自注意力做计算。最终预测的不同兴趣的物品之间计算物品与用户兴趣的内在相似性，从而合并结果，获得最终推荐序列。

![image-20250119103547733](https://github.com/NKKCCB/Rec-Home/blob/main/typora-resource/image-20250119103547733.png)

 		从图中可以看到，总体流程就是先按兴趣分类再对多兴趣聚合成一个推荐序列。

3.Deep Multifaceted Transformers for Multi-objective Ranking in Large-Scale E-commerce Recommender Systems--From CIKM2020

①动机

​	本文针对了一个比较常见的问题做了探究：目前的方法多基于点击率CTR做推荐，而忽略了其他指标：如转换率CVR。通俗理解为可能用户天天看iphone，但是并不会真正的购买。

②方法

​	![image-20250119131129673](https://github.com/NKKCCB/Rec-Home/blob/main/typora-resource/image-20250119131129673.png)

​	所以作者对三种序列（代表短期的点击序列、代表中期兴趣的购物车序列，以及代表长期的订单序列）进行Transformer编码，并对三种编码序列进行cat并输入MMOE（多门专家混合层），通过多专家网络计算任务得分。此外，由于用户点击率可能还会收到商品页码等影响，因此在训练中加入了偏差神经网络，输入的偏差包括位置偏差与相邻偏差（位置偏差指的是页码等因素，相邻偏差指用户点击会收到相邻商品影响）。

​	训练与预测:训练使用多任务的损失进行加劝，比如CTR任务预测结果与CVR任务预测结果分别计算并加权，而预测则是对多任务的预测结果加权，得出推荐结果。





​	