## 一、代码学习

模型的输入是通过采样一个batch_size的序列，在代码中，有这一句代码进行实现。

```python
sampler = WarpSampler(user_train, usernum, itemnum, batch_size=args.batch_size, maxlen=args.maxlen, n_workers=3)
```

采样方法

```python
def sample_function(user_train, usernum, itemnum, batch_size, maxlen, result_queue, SEED):
    def sample():
        # 随机从用户集中采样一个用户，用户用id来表示
        user = np.random.randint(1, usernum + 1)
        # 如果训练集中，该样本的交互历史小于1，那就重新采样
        while len(user_train[user]) <= 1: user = np.random.randint(1, usernum + 1) 
        seq = np.zeros([maxlen], dtype=np.int32) # 序列
        pos = np.zeros([maxlen], dtype=np.int32) # 用于存储交互的正样本
        neg = np.zeros([maxlen], dtype=np.int32) # 用于存储负样本
        nxt = user_train[user][-1] # 最后一个交互的物品
        idx = maxlen - 1 
        ts = set(user_train[user]) 
        for i in reversed(user_train[user][:-1]): # reversed是逆序搜索，这里的i指的是交互的物品
            seq[idx] = i
            pos[idx] = nxt
            # 为什么要设定不等于0？是为了保证当序列长度没到达maxlen时，正样本序列会补充为0，那么构成的负样本序列也应该是0
            if nxt != 0: neg[idx] = random_neq(1, itemnum + 1, ts)  
            nxt = i
            idx -= 1
            if idx == -1: break
        return (user, seq, pos, neg)
    return sample()
```

SASREC 模型输入

```python
pos_logits, neg_logits = model(u, seq, pos, neg)
```

forward中特征编码

```
log_feats = self.log2feats(log_seqs)
```

具体流程

```python
def log2feats(self, log_seqs):
        # 取出物品id对应的embedding
        seqs = self.item_emb(torch.LongTensor(log_seqs).to(self.dev))
         # 为什么要做这个操作? 其实就是乘以一个embedding维度的根号值，感觉有点类似于attention的计算除以根号d那样
        seqs *= self.item_emb.embedding_dim ** 0.5    
        # 构建出位置的矩阵
        positions = np.tile(np.array(range(log_seqs.shape[1])), [log_seqs.shape[0], 1]) #
        # 取出位置对应的embedding
        seqs += self.pos_emb(torch.LongTensor(positions).to(self.dev))
        seqs = self.emb_dropout(seqs)
        # 如果序列太短，前面等于0，那么对应的序列embedding也要等于0
        timeline_mask = torch.BoolTensor(log_seqs == 0).to(self.dev)
        seqs *= ~timeline_mask.unsqueeze(-1) # broadcast in last dim
        # 这个是为了实现论文中提到的前面物品在预测时不能用到后面物品的信息，用mask来实现
        tl = seqs.shape[1] # time dim len for enforce causality
        attention_mask = ~torch.tril(torch.ones((tl, tl), dtype=torch.bool, device=self.dev))
        # 送入模型，进行预测
        for i in range(len(self.attention_layers)):
            seqs = torch.transpose(seqs, 0, 1)
            Q = self.attention_layernorms[i](seqs)
            mha_outputs, _ = self.attention_layers[i](Q, seqs, seqs, 
                                            attn_mask=attention_mask)
                                            # key_padding_mask=timeline_mask
                                            # need_weights=False) this arg do not work?
            seqs = Q + mha_outputs
            seqs = torch.transpose(seqs, 0, 1)

            seqs = self.forward_layernorms[i](seqs)
            seqs = self.forward_layers[i](seqs)
            seqs *=  ~timeline_mask.unsqueeze(-1)
        log_feats = self.last_layernorm(seqs) # (U, T, C) -> (U, -1, C)
        return log_feats
```

作者在文中没有提及对比学习，但是在代码中有使用，会计算正负样本的损失

```python
loss = bce_criterion(pos_logits[indices], pos_labels[indices])
loss += bce_criterion(neg_logits[indices], neg_labels[indices])
```

## 二、知识

1.模型蒸馏及代码实现

先训练一个teacher网络，然后使用这个teacher网络的输出和数据的真实标签去训练student网络。知识蒸馏，可以用来将网络从大网络转化成一个小网络，并保留接近于大网络的性能；也可以将多个网络的学到的知识转移到一个网络中，使得单个网络的性能接近emsemble的结果

传统训练：当没有 Teacher 网络时候，仅仅将 data 经过 Student 网络，在softmax之后，输出概率分布值 q，将 q 与 label p 求 cross_entropy loss 就是称为 Hard loss，因为这个p是真实值的one-hot向量，q和p越接近越好。

知识蒸馏：当有 Teacher 的帮助下的时候，loss来自 Student 和 Teacher 网络。且Teacher 输出的 q' 要经过带温度的Softmax之后（让它更加平滑，思想类似于label smooth）得到 q'' 再与 q 求loss，总loss = Teacher q'' 和 Student q 的 loss + Student q 和 label p 的 loss。

![image-20250128123453391](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250128123453391.png)

其核心蒸馏损失的计算如下:

```python
def distillation_loss(y,labels,teacher_scores,temp,alpha):
	soft_loss = nn.KLDivLoss()(F.log_softmax(y/temp, dim=1), F.softmax(teacher_scores/temp,dim=1))
	hard_loss = F.cross_entropy(y,labels)
    return soft_loss *(temp*temp*2.0*alpha) + hard_loss *(1. - alpha)

```

2.胶囊网络

2.1原理

胶囊网络的设计初衷主要来自于解决两个问题：**局部敏感性**和**层次结构解析能力的不足**。胶囊网络的设计初衷主要来自于解决两个问题：**局部敏感性**和**层次结构解析能力的不足**。

局部敏感性：传统的 CNN 在图像识别任务中表现优秀，但它们对于输入的微小变化非常敏感。例如，稍微旋转或平移一个图像可能导致 CNN 的输出发生显著变化。层次结构解析能力的不足：CNN 主要关注局部特征，并可能忽略这些特征如何在更高层次上组织成有用的结构。这就导致了它们在理解复杂空间层次关系方面的不足。

![image-20250131122456469](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250131122456469.png)

胶囊网络输出是一个高维向量。这个输出向量的模长通常用于表示某种特定特征是存在概率，而向量的方向则用于编码该特征的更多属性：如位置、方向、大小等。

动态路由：能够在不同胶囊之间传递信息，从而使得网络能够更好地理解对象的内部组成结构和**相对**空间关系。

胶囊网络中的 “胶囊” 是一组神经元，其输出为向量。向量的长度可表示实体的某种属性（如物体的存在概率），向量方向则代表实体的其他特性（如物体的姿态等） 。动态路由根据输入信息调整不同胶囊之间的连接强度。较低层胶囊的输出会根据与较高层各个胶囊的 匹配度，动态分配权重并传递信息，以确定哪些特征更重要。

2.2代码实现

动态路由 通过迭代优化路由权重，增强胶囊间的一致性

```python
def dynamic_routing(logits, num_iterations=3):
    b = torch.zeros_like(logits) #路由权重初始化为零
    for i in range(num_iterations):  
        c = F.softmax(b, dim=2)  # 通过Softmax函数计算路由权重	
        s = (c * logits).sum(dim=1)
        v = squash(s)  # 使用squash函数将s压缩为非线性向量，归一化
        if i < num_iterations -1:  # #计算预测向量与输出向量的相似度，用于更新路由权重，多次迭代
            agreement = (logits * v.unsqueeze(1)).sum(dim=3)
            b = b + agreement
    return v
```

网络forward

```python
 def forward(self, x, y=None):
        x = F.relu(self.conv1(x))
        x = self.primary_capsules(x) # 卷积层输出n个xx维向量，然后展平
        batch_size = x.size(0)
        x = x.view(batch_size, self.num_primary_capsules, self.primary_capsule_dim)
        x = squash(x)
        digit_caps = self.digit_capsules(x)  # 数字胶囊层，输出n个xx维的胶囊,n对应兴趣数量
        probs = digit_caps.norm(dim=2)
        if y is None: 
            _, max_length_indices = probs.max(dim=1)
            y = torch.eye(10).to(x.device).index_select(dim=0, index=max_length_indices)
        recon = self.decoder((digit_caps * y.unsqueeze(2)).view(batch_size, -1)) # 解码器，用于重建输入
        recon = recon.view(-1, 1, 28, 28)
        return probs, recon

```

三、论文阅读

1.MM-Rec: Multimodal News Recommendation--From SIGIR2022

![image-20250201173040031](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250201173040031.png)

①动机。作者围绕多模态新闻推荐优势阐述了两点：a.用户点击会受图片与标题两方面影响 b.用户具有多兴趣，点击的新闻可能可能仅与某一兴趣有关，进行候选新闻与点击新闻的跨模态建模可以更好的分析相关性

②做法：用预训练的mask-rcnn提取roi，再对每个感兴趣区域用resnet提取特征，最终序列长度就是roi的数量。对序列建模，最终序列长度就是词长度。用预训练的 ViLBERT 模型捕捉标题和图像的内在相关性，通过co- Transformer 学习隐藏表示序列。再利用词注意力网络和图像注意力网络分别得到新闻标题和图像的最终表示。

为了解决点击新闻与候选新闻的匹配问题（去噪），作者提出了一个candidate-aware attention network 

![image-20250201172421112](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250201172421112.png)

![image-20250201172437147](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250201172437147.png)

将候选文本与点击图片、点击文本与候选图片计算权重（向量投影），并作为用户的兴趣表征

![image-20250201172837025](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250201172837025.png)

最终根据用户表征与候选新闻的图片表征、文本表征计算权重（理解为向量投影，即相似度），计算出预测分数

2.When Multi-Level Meets Multi-Interest: A Multi-Grained Neural Model for Sequential Recommendation--From SIGIR2022

![image-20250201110944213](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250201110944213.png)

①动机。现有的方法遵循两个方向改进序列推荐：a.对多兴趣进行聚类，并根据历史item的聚类结果进行推荐  b.利用图卷积对历史item之间的关系进行建模。本文则是期望提出一个结合多兴趣学习和多层级图卷积聚合二者优势的框架，能够解决不同颗粒度下的多兴趣问题。

②做法。作者首先将历史item转换为全连接的图，并使用capsnet进行更新，形成自适应图结构（不同商品之间的距离根据用户嵌入以及两个商品的嵌入联合计算得到。用户嵌入被用来实现用户感知的图构建，相同的两个商品对对于不同的用户可能具有不同的相关性值）。通过GCN提取多级商品表征（ L 层），每一层输出的商品表征代表不同层级的商品信息，对应着后续提取不同层级的用户兴趣

<img src="C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250201174851118.png" alt="image-20250201174851118" style="zoom:50%;" />

在提取多级商品表征后，模型利用胶囊网络对用户每个层级的历史商品序列分别提取出 K 个兴趣向量。为了补充胶囊网络中的时序问题，作者采用 BiLSTM 对序列进行时序编码，模型利用带有时间特征的输出对动态路由的权重通过残差结构进行更新。最终，每个层级的序列商品表征都经过序列胶囊网络得到对应用户的 K 个兴趣向量。

在预测时对于L个层级的K个向量，作者使用池化获取最大概率的，作为最终预测的兴趣结果。

![image-20250201175217184](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250201175217184.png)



3.Pre-training Graph Transformer with Multimodal Side Information for Recommendation --From ACM MM

![image-20250201180814847](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250201180814847.png)

①动机。本文动机概括如下：利用side-information进行多模态自监督预训练，并且提出了名为MCNSampling的算法用于处理大规模的图数据

②做法。

PMGT包含四个主要组件：上下文邻居采样、点嵌入初始化、Transformer编码器、图重建

上下文邻居采样： 对于每个节点h，图中都存在一些相关的节点，这可能有助于丰富其表示。这些相关的节点被称为h的上下文邻居。为了在PMGT训练过程中有效地选择一批节点的上下文邻居，我们开发了一种名为MCN采样的采样算法。

点嵌入初始化： 在邻域采样后，将目标节点h与其有序的上下文邻域Sh连接起来，并加入了位置id embedding以记住位置信息

Transformer编码器：使用Transformer框架来建模一个节点与其上下文邻居之间的相关关系。

最终预训练流程如下：对item H进行上下文采样（每次都是从一个小批次数据中采样，H是个带有各种side information的节点），接着进行embedding为序列，对H的上下文进行随机掩码，例如掩盖20%的item，预测目标有两个：图结构、掩码节点特征。

<img src="C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250201190515432.png" alt="image-20250201190515432" style="zoom:50%;" />

<img src="C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250201190531937.png" alt="image-20250201190531937" style="zoom: 50%;" />

进行损失相加

<img src="C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250201190556201.png" alt="image-20250201190556201" style="zoom:50%;" />

