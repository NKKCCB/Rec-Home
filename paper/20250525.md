## 1.python新特性

<img src="C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250525154000240.png" alt="image-20250525154000240" style="zoom: 67%;" />

等同于：

![image-20250525153949019](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250525153949019.png)

## 2.deepseed

​	DeepSpeed是一个由微软开发的开源深度学习优化库，旨在**提高大规模模型训练的效率和可扩展性**。它通过多种技术手段来加速训练，包括模型并行化、梯度累积、动态精度缩放、本地模式混合精度等



## 3.In-context learning

​	In-context Learning 语境学习是一种学习范式，是现代自然语言处理领域中一种重要的学习方法，尤其在使用大规模，尤其在使用大规模预训练模型时，它允许模型在给定的上下文中进行学习和推理，而无需真正更新模型参数。

**In-context Learning的工作原理**

提示词和示例

**提示词**：ICL常通过提示词来引导模型的生成过程，提示词通常包括任务描述，问题陈述或请求模型执行的操作。‍‍‍‍‍‍‍‍‍
示例：在少样本学习(Few-Shot Learning)中，提示词可能包括一些示例输入和输出，帮助模型理解如何处理类似的任务。‍‍
上下文提供

**任务描述**：在ICL中，任务描述用于告诉模型要完成的任务，例如：生成一个关于人工智能的总结。‍‍‍‍‍
示例输入输出：提供几个示例输入和输出对，可以帮助模型理解特定任务的模式或要求，例如：给出一些翻译示例来帮助模型进行语言翻译。‍‍
推理和生成‍‍‍

**推理**：模型根据提供的上下文进行推理，生成与上下文相关的响应或输出。‍‍‍‍‍‍
生成：在ICL中，生成的文本基于模型对上下文的理解，以及预训练中学到的知识‍‍‍

## 4.[Bi-encoder vs Cross encoder? - 青铜时代的猪 - 博客园](https://www.cnblogs.com/wanger-sjtu/p/18227082)

or这个网址 ： https://wanger-sjtu.github.io/encoder-cross-bi/

## 5.Retrieval-based Language Models 





## 6.[DPO: Direct Preference Optimization 直接偏好优化](https://www.cnblogs.com/lemonzhang/p/17910358.html)

## 7.Scaling Laws 

Scaling Laws的核心是：**模型性能主要取决于参数量（N）、数据量（D）和计算量（C）**。在其他条件相近时，这三大要素的变化会引起模型性能以**可预期的方式**改变。

**Scaling Laws 在实践中具有重要指导意义：**

- ***预测和规划模型训练：\*** 通过在小规模模型上实验并拟合Scaling Law，研究者可以**预测更大模型的性能**，从而决定训练多大的模型、用多少数据，以高效利用有限的计算预算。例如，在构建“前沿”大模型时，通常会先确定可用的算力预算（如总共可执行多少FLOPs），再利用Scaling Law计算出**理想的参数量和数据集大小**。然后据此设计模型和准备数据，进行预训练直至耗尽既定算力为止。这种方法已成为业界训练数百亿甚至上千亿参数模型的基础流程。
- ***优化资源分配：\*** Scaling Law揭示了**参数规模、数据规模与算力之间的最佳配比**。OpenAI的研究发现，在给定计算预算下，与其训练一个小模型用尽海量数据，不如训练一个**更大的模型**但**适度早停**更为高效。更大的模型对数据的**样本效率**更高——达到同等性能所需的训练步骤和数据更少。因此，在资源受限的情况下，通常应优先增加模型参数，而非一味增加训练轮数或数据量。这一指导原则直接影响了GPT-3等模型的训练策略：OpenAI据此大胆地构建了千亿级参数模型，并在训练未完全收敛时就停止，结果证明大型模型依然取得了优秀性能。
- ***评估模型扩展性：\*** 通过Scaling Law，可以评估模型性能是否达到了当前规模的**饱和点**。如果模型仍遵循预期的幂律提升，则意味着增加规模仍有益；反之，如果性能提升出现停滞或偏离幂律曲线，则提示可能需要调整策略（如改进模型架构或算法）而不仅仅是“堆料”扩展。

## 8.[KL散度理解以及使用pytorch计算KL散度 - 知乎](https://zhuanlan.zhihu.com/p/339613080)

## 9：held-in held-out

.held-in evaluation内部评估，使用同一数据集进行训练和评估，通常采用交叉验证技术将数据集划分为训练集和验证集。模型会在训练集上进行训练，并使用验证集上的数据进行评估和调优。可能导致过度拟合。
held-out evaluation：外部评估，使用独立的、未参与训练的数据集进行评估的。测试泛化能力。

## 10.F1 这会别忘了额

![image-20250529163321555](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250529163321555.png)

## 11.解决使用git时遇到Failed to connect 

Failed to connect to github.com port 443 after 21090 ms: Couldn‘t connect to server[解决使用git时遇到Failed to connect to github.com port 443 after 21090 ms: Couldn‘t connect to server_git couldn't connect to server-CSDN博客](https://blog.csdn.net/qq_40296909/article/details/134285451)