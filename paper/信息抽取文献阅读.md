#### 一、RUIE: Retrieval-based Unified Information Extraction using Large Language Model--ACL2025[llm+rag]

1.动机

![image-20250525201157684](C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250525201157684.png)

copyright:豆包

2.方法

x是输入y是输出，冻结大模型参数，用很多组输入输出，得到n个输出，x包括指令I+文本输入（指令I的内容如下）。得到输出之后呢，评估得到GT的概率。用这个来选指令，看看 哪个指令得到GT的概率最高。好的指令当正样本，差的指令当负样本

Task: Named Entity Recognition
Schema: [location, person, organization]
Input: The Parkinsons are a punk rock band originally from Coimbra, Portugal, formed in the
year 2000 and based in London, known for their outrageous live performances.
Output: location: Coimbra; location: Portugal; location: London.

<img src="C:\Users\ZhuanZ\AppData\Roaming\Typora\typora-user-images\image-20250529112435628.png" alt="image-20250529112435628" style="zoom: 50%;" />



a.RUIE 与传统检索方法的核心区别是什么？

**答案**：RUIE 是首个针对 UIE 的**可训练检索框架**，通过以下创新实现统一多任务处理：

- **多任务候选池**：包含 NER/RE/EE 等多任务示例，而非单一任务。
- **双重监督信号**：结合**LLM 偏好评分**（捕捉模型对示例的隐含偏好）和**关键词增强奖励模型**（对齐实体 / 关系细粒度信息），而非仅依赖语义相似度。
- **端到端训练**：通过对比学习和知识蒸馏优化双编码器检索器，支持高效推理。

b.BM25?

BM25（Best Matching 25）是一种经典的**概率检索模型**，广泛应用于信息检索系统中，用于衡量查询与文档之间的相关性。其核心思想是通过词频、逆文档频率（IDF）和文档长度归一化等因素，量化文本间的匹配程度，适用于关键词匹配、文档排序等任务。

文中初始化候选集：
在训练阶段，利用 BM25 从多任务候选池（包含 NER/RE/EE 等任务数据）中快速检索出与输入文本语义相关的初始候选示例（如 Top 100 个），降低后续 LLM 评分的计算成本

#### 二、Retrieval augmentation for text-to-table generation--TIOS2025--组内

##### **2.1 文本匹配（TeM）**

- **检索机制**：使用 BM25 算法从训练集检索与输入文本最相似的文本 - 表格对（排除自身）。
- **输入增强**：通过模板`"example text: Xs; example table: Ts; test text: X"`拼接检索结果与原始输入，引导表头生成和内容推导。

##### **2.2 迭代表格生成（ITG）**

- **初始生成**：基于 TeM 增强输入生成初步表格。
- **迭代检索**：将生成表格作为查询，再次检索训练集获取更相关的表格 - 文本对，进一步增强输入（如添加表头结构`"guiding plan: Struct(Ttab)"`）。
- **终止条件**：当生成表格不再变化时停止迭代，确保结构和值的准确性。

##### **2.3 噪声感知学习（NaL）**

- **噪声注入**：训练时以 15% 概率随机替换真实表头为检索表中无关表头，模拟迭代过程中可能的噪声。
- **鲁棒性提升**：迫使模型区分有效辅助信息，避免盲目复制错误结构，提升生成稳定性。

##### **问题 1：Ragtable 如何解决传统方法的表头生成困难？**

**答案**：通过 ** 文本匹配（TeM）** 检索训练集中相似文本 - 表格对，将其表头结构作为辅助输入（如模板拼接），引导模型学习潜在表头模式。例如，当输入文本缺乏 “subtitle” 等信息时，检索到的表格可提供该表头作为生成参考，避免仅依赖原始文本的局限性。

##### **问题 2：迭代表格生成（ITG）的具体流程和优势是什么？**

**答案**：流程为：



1. 用 TeM 生成初步表格；
2. 将初步表格作为查询，检索训练集获取更相关的表格 - 文本对；
3. 拼接新辅助信息后再次生成，重复直至结果稳定。
   优势在于**多轮检索优化**：通过生成表格的语义匹配，逐步逼近真实结构，尤其在表头和复杂值生成上更精准。实验显示，ITG 使检索表头与真实表头的 Jaccard 系数提升显著，低相似度（0-0.25）比例下降。

##### **问题 3：噪声感知学习（NaL）如何提升模型鲁棒性？**

**答案**：NaL 在训练中以 15% 概率随机替换真实表头为无关噪声（如检索表中不存在于真实表的表头），迫使模型学习区分有效信息。例如，当生成过程中混入错误表头 “country” 时，模型需通过噪声鲁棒性机制抑制该错误，优先选择真实表头 “awarding organisation”。此机制使模型在迭代中避免盲目依赖检索结果，提升对噪声输入的容错能力，实验表明 NaL 使非表头单元格 F1 提升约 2%。

