<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>paper阅读20250102</title></head>
<body><h4>一、Poisoning Self-supervised Learning Based Sequential Recommendations</h4>
<h5>1.研究动机 </h5>
<p>在计算机视觉领域，SSL 已被证明容易受到中毒攻击，而基于 SSL 的推荐系统中的中毒攻击尚未被研究。</p>
<h5>2.方法</h5>
<p>	推荐系统的中毒攻击可分为两种： 非针对性攻击和针对性攻击。非针对性攻击目标是降低系统性能，而本文则是后者:通过有毒数据，使得特定item更易被推荐/不推荐。</p>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215135733210.png" referrerpolicy="no-referrer" alt="image-20241215135733210"></p>
<p>	    本文方法部分可概括如下：通过gan生成假的样本序列，并通过对比学习进行自监督预训练。而推荐系统的自监督预训练与CV略有不同，CV中通过对图片裁剪、旋转、颜色变换、模糊等方式形成样本对，在推荐系统中则通过mask部分item形成正负样本，同一序列不同方式的mask后组成正样本，反之则为负样本对。在本文的Poisoning Attack中将gan生成的假序列与正序列当成相似对（正样本），优化loss。</p>
<p>	    这里疑惑的点在于，gan的生成无法保证生成的序列一定包含目标item，而part c中对此做出了方法阐述:通过生成序列与目标序列计算loss并梯度更新（例如，生成的[1,2,3,4,5],给的标签是[5,5,5,5,5],这样在优化时便更易生成包含5的序列），使得生成的fake序列包含更多的目标item。这里也有个很明显的问题，这个任务太过简单容易过拟合，因此作者在给定的标签中加入了概率阈值p（这里猜测应该是借鉴了dropout的处理方式）</p>
<p>		本文在下游任务中，验证自己Poisoning Attack预训练的参数有效性，混入1%数据进行下游任务fintune的效果验证，与原始数据相比预测的概率提升了一个数量级。</p>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215142755210.png" referrerpolicy="no-referrer" alt="image-20241215142755210"></p>
<h5>3.贡献点</h5>
<p>	将中毒攻击引入推荐学习ssl，并充分验证可行性和有效性。</p>
<h4>二、Towards Multi-Interest Pre-training with Sparse Capsule Network</h4>
<h5>1.研究动机 </h5>
<p>		用户兴趣具有动态、上下文相关等特性，且在不同域中表现复杂，常见的预训练将每个用户表示为一个固定的向量，无法捕捉用户的不同兴趣，本文研究目标是设计面向多兴趣预训练的胶囊网络。</p>
<p>		文中对研究的多兴趣预训练框架提出了以下目标：</p>
<p>		①对通用空间中对多样化、上下文相关和时间性的用户兴趣进行建模。文中表述现有的预训练模型通常采用类似于 GPT 的自回归架构，这可能会阻碍上下文信息建模以实现普遍的用户理解。这里我的理解是，GPT的预训练是单向推理生成，无法双向建模，例如将上文item与下文item建立双向的全局上下文关系。</p>
<p>		②设计适用于多兴趣学习下游任务的预训练pretext task。</p>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215145153762.png" referrerpolicy="no-referrer" alt="image-20241215145153762"></p>
<h5>2.方法</h5>
<p>		提出的多兴趣预训练框架预训练阶段包含两部分： 文本感知项目嵌入（理解为序列文本的特征建模）以及稀疏兴趣胶囊网络</p>
<p>		文本感知项目嵌入包括三部分：</p>
<p>		①文本编码器，该部分加载BERT的预训练参数，并且该部分参数冻结，仅用作特征提取。</p>
<p>		②MOE模块，用于将不同域的语义知识进行统一，这里原理不太熟悉，有待学习。通过代码可以看到，实质上就是将输入进行全连接,然后cat之后加噪声取均值（感觉类似于Transformer的多头注意力机制中多头multi head的处理，通过全连接，不同的head关注不同的方面）。		</p>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215170152136.png" referrerpolicy="no-referrer" alt="image-20241215170152136"></p>
<p>		③Transformer编码器模块。对语义知识进一步编码，这里是主要的参数学习部分。</p>
<p>		 稀疏兴趣胶囊网络主要流程如下：生成基向量矩阵以构建通用兴趣空间，对于给定用户的每个项目 h,计算其与每个基向量相似度，激活兴趣胶囊，确定用户兴趣数量并初始化动态路由耦合系数。后续通过全连接层获取潜在兴趣特征，经动态路由计算胶囊输出，作为用户兴趣表示。</p>
<p>		这一块实现逻辑相较其他部分比较复杂，不是特别理解，后续应单独阅读胶囊网络相关论文，补全知识。</p>
<p>		模型的预训练遵循常见的对比学习范式，微调时冻结编码器参数，只训练解码器（本人自监督实验中也是fintune时冻结编码器，只训练解码器）。</p>
<h4>三、Disentangle interest trend and diversity for sequential recommendation</h4>
<h5>1.研究动机 </h5>
<p>		作者总结现有方法存在问题：一是未区分兴趣趋势和兴趣多样性，同时建模会导致性能下降；二是在兴趣预测中消除item多样性会造成信息损失，因为这些项可能代表用户潜在兴趣。因此，本文研究目标为将兴趣趋势与兴趣多样性解耦，以提升推荐效果。作者指出<strong>兴趣趋势与兴趣多样性的目标在某种程度上相互冲突</strong>，这里本人较为疑惑：这里的结论似乎文中没有实验做支撑，不知道是不是已有研究验证了这一结论，有待进一步学习研究。</p>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215212243131.png" referrerpolicy="no-referrer" alt="image-20241215212243131"></p>
<h5>2.方法</h5>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215212923838.png" referrerpolicy="no-referrer" alt="image-20241215212923838"></p>
<p>		因此本文的做法总结如下：将用户的历史item从兴趣趋势和兴趣多样性两个方面进行建模，各自得出预测score并进行加权从而得出最终结果。</p>
<p>		本文较为核心的点在于如何将序列拆分为 兴趣趋势序列 与 兴趣多样性序列。这里可以看到，作者取最近的c项作为最近的趋势倾向，然后计算每一项与最近c项的余弦相似度（也就是a在b上的投影，值越接近1越相似，类似于transformer的q×k），相似度与设定的阈值比较，大于阈值该处mask就是1，以此来获取兴趣趋势序列。而兴趣多样性序列此处没说怎么分类，可能剩下的都作为了兴趣多样性序列。</p>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215223251663.png" alt="image-20241215223251663" style="zoom:67%;" /></p>
<p>		然后对于兴趣趋势序列用TCN编码，兴趣多样性序列用简单的MLP对item编码并获取最大值（使用常规的sigmoid函数），对两个模块的输出score使用简单的线性插值函数加权输出结果。</p>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215224611143.png" referrerpolicy="no-referrer" alt="image-20241215224611143"></p>
<p>			从结果来看，效果还是很明显的。特别是在排序指标NDCG上取得较大的提升，也证明了兴趣趋势模块的有效性。</p>
<h4>四、Spectral and Geometric Spaces Representation Regularization for Multi-Modal Sequential Recommendation</h4>
<h5>1.研究动机 </h5>
<p>		多模态信息在对序列推荐任务有较大帮助，但多模态推荐存在计算成本高和表示退化问题。本文拟通过轻量化 Transformer 模块和可扩展注意力机制，融合多模态信息。本文也是在Transformer的计算上进行研究，优化其在序列推荐任务上的性能。</p>
<p>		</p>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215232841505.png" alt="image-20241215232841505" style="zoom: 50%;" /></p>
<h5>2.方法</h5>
<p>		下图把原始的Transformer与本文的做了对比，可见本文在qkv的处理上进行了改进（Transformer的主要可学习参数与运算都发生在 输入全连接成qkv以及qkv的矩阵相乘上）。</p>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215233530659.png" alt="image-20241215233530659" style="zoom:67%;" /></p>
<p>		按照文中表述，用两个可学习的重缩放向量代替了自注意力组件中 query、key、value 的线性投影操作以及前馈网络 （FFN） 层中的第二次线性变换。这里没有怎么阅读paper,更加感兴趣于代码的实际运算处理上，本文核心的改动逻辑如下：</p>
<p>		<img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215235414867.png" referrerpolicy="no-referrer" alt="image-20241215235414867"></p>
<p>		这里说实话并不是很理解，corr * self.scale_w.unsqueeze(-1).unsqueeze(0)  仅仅对QK所得矩阵用一个可学习向量进行逐个元素的点乘，理论上不会影响参数的计算量，为什么最终会大幅节省gpu内存占用率？此处有待结合实验深入学习</p>
<p>		本文Transformer另一个魔改的点   融合多模态的交叉注意力机制，印象中在其他论文（特别是多模态相关的）中有过相似的处理，此处不做赘述，本质上都是多模信息全连接 所得qkv之间的矩阵运算</p>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215233106829.png" alt="image-20241215233106829" style="zoom: 50%;" /></p>
<h4>五、DiffuRec: A Diffusion Model for Sequential Recommendation</h4>
<h5>1.研究动机</h5>
<p>将扩散模型应用于序列推荐</p>
<p>文章从四个部分阐述了，为什么研究把扩散模型应用于序列推荐？</p>
<p>①一个item可能具有多个类别，单个向量不好做编码。</p>
<p>②用户的兴趣多样性不适合静态项目表示</p>
<p>③用户当前的兴趣是不确定的，更适合用将兴趣建模为分布（扩散模型的加噪去噪训练目标就是学习input的数据分布）</p>
<p>④涉及目标item的交互需要优化（这里不理解,有待学习）</p>
<h5>2.方法</h5>
<p>		这里的扩散模型主体流程与传统的扩散模型类似，正向逐步加噪并采样，反向过程拟合噪声并最小化损失。</p>
<p>		CV领域的扩散模型多基于Unet架构，而本文使用的是Transformer架构做主干网络。之前认为扩散模型正向加噪与反向去噪的过程需要Unet类型的对称结构，读了这篇论文之后查了下现在的扩散模型很多都是基于Transformer的，之前对扩散模型理解有误。</p>
<p>		对于损失计算，文中提出扩散模型的标准目标函数不适合用于推荐任务，item的embedding不是连续分布的，因此在扩散阶段利用交叉熵损失进行模型优化（通过顺序推荐的内积计算两个向量之间的相关性）</p>
<h4>六、TEXT CAN BE FAIR: Mitigating Popularity Bias with PLMs by Learning Relative Preference</h4>
<h5>1.研究动机 </h5>
<p>		推荐模型常依赖用户行为训练，而用户行为稀疏且二元，导致模型易受流行度偏差影响，倾向推荐热门物品，使长尾物品曝光不足，形成恶性循环。现有的利用物品文本语义虽对长尾item有帮助，但仍受流行度偏差影响(作者在主流方法上进行长尾问题的实验，证明当前主流方法均表现不佳)</p>
<h5>2.方法</h5>
<p><img src="C:\Users\Dunker\AppData\Roaming\Typora\typora-user-images\image-20241215203703275.png" referrerpolicy="no-referrer" alt="image-20241215203703275"></p>
<p>		用预训练语言模型构建 PLMRec 作为偏好排序器和推荐模型的骨干网络</p>
<p>		在偏好排序器模型中分为两个阶段训练：第一阶段用实例采样预训练，捕捉数据集中的常见的排序模式；第二阶段用目标采样微调，冻结语言模型参数仅更新 MLP，获取偏好排序器模型参数。可以理解为一阶段训练编码器能力，二阶段训练解码器能力。在下面的蒸馏中，编码器、解码器参数直接使用，进行知识迁移。</p>
<p>		在自蒸馏阶段，将排序器模型视为 RLHF 中的奖励模型，为推荐模型训练提供额外监督信号，避免长尾物品训练不足。作者提出了三种蒸馏策略：成对蒸馏（学习随机负样本与真实物品间的相对偏好，计算成对蒸馏损失）、硬蒸馏（直接匹配排序器模型中排名最高的物品进行监督，计算硬蒸馏损失）、软蒸馏（推荐模型匹配真实物品和负样本的相对偏好排名，通过最小化两个概率分布的 KL 散度计算软蒸馏损失）。实验证明成对蒸馏和软蒸馏在去除流行度偏差影响表现较好</p>
</body>
</html>